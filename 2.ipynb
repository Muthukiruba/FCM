{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "img_path=\"C:/Users/Admin/Desktop/datasets/lung.jpg\"\n",
    "img = skimage.io.imread(img_path)/255.0\n",
    "\n",
    "def plotnoise(img, mode, r, c, i):\n",
    "    plt.subplot(r,c,i)\n",
    "    if mode is not None:\n",
    "        gimg = skimage.util.random_noise(img, mode=mode)\n",
    "        plt.imshow(gimg)\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.title(mode)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(18,24))\n",
    "r=4\n",
    "c=4\n",
    "plotnoise(img, \"gaussian\", r,c,1)\n",
    "plotnoise(img, \"localvar\", r,c,2)\n",
    "plotnoise(img, \"poisson\", r,c,3)\n",
    "plotnoise(img, \"salt\", r,c,4)\n",
    "plotnoise(img, \"pepper\", r,c,5)\n",
    "plotnoise(img, \"s&p\", r,c,6)\n",
    "plotnoise(img, \"speckle\", r,c,7)\n",
    "# plotnoise(img, None, r,c,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the input image\n",
    "img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/original_image.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Reshape the image to a vector\n",
    "data = img.reshape((-1, 1))\n",
    "\n",
    "# Normalize the data to the range [0, 1]\n",
    "data = data.astype(float) / 255.0\n",
    "\n",
    "# Fuzzy c-means clustering\n",
    "n_clusters = 3\n",
    "cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(data.T, n_clusters, 2, error=0.005, maxiter=1000, init=None)\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster_centers = cntr\n",
    "\n",
    "# Calculate the KL divergence-based fuzzy membership\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "memberships = np.zeros((data.shape[0], n_clusters))\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(n_clusters):\n",
    "        memberships[i, j] = kl_divergence(data[i], cluster_centers[j])\n",
    "\n",
    "# Normalize the memberships\n",
    "memberships = memberships / memberships.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Reshape the memberships to the original image shape\n",
    "memberships = memberships.reshape(img.shape[0], img.shape[1], n_clusters)\n",
    "\n",
    "# Select the cluster with the maximum membership for each pixel\n",
    "segmented_img = np.argmax(memberships, axis=2)\n",
    "\n",
    "# Display the segmented image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "# Fuzzy c mean with kl divergence\n",
    "plt.imshow(segmented_img, cmap='gray')\n",
    "plt.title('Segmented Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def pfcm(image, n_clusters, max_iter=1, m=2, alpha=1, error=1e-5):\n",
    "    # Reshape the image to a vector\n",
    "    data = image.reshape((-1, 1))\n",
    "    \n",
    "    # Normalize the data to the range [0, 1]\n",
    "    data = data.astype(float) / 255.0\n",
    "    \n",
    "    # Number of pixels\n",
    "    n_pixels = data.shape[0]\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    centroids = np.random.rand(n_clusters, data.shape[1])\n",
    "    \n",
    "    # Initialize membership, noise robustness, and spatial neighborhood matrices\n",
    "    u = np.random.rand(n_pixels, n_clusters)\n",
    "    eta = np.zeros((n_pixels, n_clusters))\n",
    "    xi = np.zeros((n_pixels, n_clusters))\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # Update membership\n",
    "        for i in range(n_pixels):\n",
    "            for j in range(n_clusters):\n",
    "                u_sum = np.sum((np.linalg.norm(data[i] - centroids[j]) / np.linalg.norm(data[i] - centroids[k])) ** (1 / (m - 1)) for k in range(n_clusters))\n",
    "                u[i, j] = (1 - eta[i, j] - xi[i, j]) / u_sum\n",
    "        \n",
    "        # Update centroids\n",
    "        memberships = (u / (1 - eta - xi)) ** m\n",
    "        centroids_new = np.dot(memberships.T, data) / np.sum(memberships, axis=0)[:, None]\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(centroids_new - centroids) < error:\n",
    "            break\n",
    "        \n",
    "        centroids = centroids_new\n",
    "    \n",
    "        # Update noise robustness and spatial neighborhood matrices\n",
    "        for i in range(n_pixels):\n",
    "            for j in range(n_clusters):\n",
    "                eta_sum = np.sum(xi[i, k] for k in range(n_clusters))\n",
    "                eta[i, j] = 1 - xi[i, j] - ((n_clusters - 1) / n_clusters) * (eta_sum / np.sum((u[i, j] / u[i, k]) * ((np.linalg.norm(data[i] - centroids[j]) / np.linalg.norm(data[i] - centroids[k])) ** (1 / (m - 1))) for k in range(n_clusters)))\n",
    "                xi[i, j] = 1 - (u[i, j] + eta[i, j]) - (1 - (u[i, j] + eta[i, j]) ** alpha) ** (1 / alpha)\n",
    "    \n",
    "    # Reshape the memberships to the original image shape\n",
    "    memberships = u.reshape(image.shape[0], image.shape[1], n_clusters)\n",
    "    \n",
    "    # Select the cluster with the maximum membership for each pixel\n",
    "    segmented_img = np.argmax(memberships, axis=2)\n",
    "    \n",
    "    return segmented_img\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread(\"C:/Users/Admin/Desktop/datasets/original_image.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply PFCM clustering\n",
    "n_clusters = 3\n",
    "segmented_image = pfcm(image, n_clusters)\n",
    "\n",
    "# Display the segmented image\n",
    "plt.imshow(segmented_image, cmap='gray')\n",
    "plt.title('Segmented Image')\n",
    "# plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91449c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d271b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=5):\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "# Image path\n",
    "img_path = \"C:/Users/Admin/Desktop/datasets/lung.jpg\"\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# Add Gaussian noise to the image\n",
    "noisy_image = add_gaussian_noise(image)\n",
    "\n",
    "# Plot the original and noisy images\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6d34f",
   "metadata": {},
   "source": [
    "# Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(noisy_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Noisy Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply median filter to remove noise\n",
    "denoised_image = cv2.medianBlur(noisy_image, 5)\n",
    "plt.imshow(cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Denoised Image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed746e1",
   "metadata": {},
   "source": [
    "# Salt and pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa10ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(image, salt_ratio=0.05, pepper_ratio=0.05):\n",
    "    \"\"\"\n",
    "    Adds salt and pepper noise to an image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image.\n",
    "        salt_ratio (float): Ratio of salt noise (default: 0.05).\n",
    "        pepper_ratio (float): Ratio of pepper noise (default: 0.05).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Image with salt and pepper noise.\n",
    "    \"\"\"\n",
    "    row, col, _ = image.shape\n",
    "    salt = np.random.rand(row, col) < salt_ratio\n",
    "    pepper = np.random.rand(row, col) < pepper_ratio\n",
    "    noisy_image = np.copy(image)\n",
    "    noisy_image[salt] = 1\n",
    "    noisy_image[pepper] = 4\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "# Add salt and pepper noise\n",
    "spimage = add_salt_and_pepper_noise(image)\n",
    "plt.imshow(cv2.cvtColor(spimage, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Noisy Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee781c9b",
   "metadata": {},
   "source": [
    "# Impulse Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_impulse_noise(image, intensity=20):\n",
    "    noisy_image = np.copy(image)\n",
    "    num_pixels = int(image.size * intensity / 100)  # Calculate the number of pixels based on intensity percentage\n",
    "    pixels_to_change = np.random.choice(image.size, num_pixels, replace=False)\n",
    "    noisy_image.flat[pixels_to_change] = np.random.randint(0, 256, num_pixels)\n",
    "    return noisy_image\n",
    "# Add impulse noise to the image\n",
    "noisy_image_impulse = add_impulse_noise(image, intensity=20)\n",
    "plt.imshow(cv2.cvtColor(noisy_image_impulse, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Noisy Image (Impulse)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5675beb",
   "metadata": {},
   "source": [
    "# Speckle Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_speckle_noise(image, mean=0, std=0.5):\n",
    "    \"\"\"\n",
    "    Add speckle noise to an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image.\n",
    "        mean (float): Mean of the noise (default: 0).\n",
    "        std (float): Standard deviation of the noise (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Image with speckle noise.\n",
    "    \"\"\"\n",
    "    row, col, ch = image.shape\n",
    "    gauss = np.random.normal(mean, std, (row, col, ch))\n",
    "    noisy_image = image + image * gauss\n",
    "    return noisy_image\n",
    "# Convert the input image to a suitable data type (e.g., 8-bit unsigned integer)\n",
    "# Convert the input image to a suitable data type (e.g., 8-bit unsigned integer)\n",
    "noisy_image_speckle = add_speckle_noise(image)\n",
    "image_uint8 = cv2.convertScaleAbs(noisy_image_speckle)\n",
    "\n",
    "# Display the noisy image with speckle noise\n",
    "plt.imshow(cv2.cvtColor(image_uint8, cv2.COLOR_BGR2RGB))\n",
    "# plt.title('Speckle Noise')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8847f",
   "metadata": {},
   "source": [
    "# Rician Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rician_noise(image, mean=0, std=2):\n",
    "    \"\"\"\n",
    "    Add Rician noise to an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image.\n",
    "        mean (float): Mean of the Gaussian noise (default: 0).\n",
    "        std (float): Standard deviation of the Gaussian noise (default: 0.1).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Image with Rician noise.\n",
    "    \"\"\"\n",
    "    row, col, ch = image.shape\n",
    "    X = np.random.normal(mean, std, (row, col, ch))\n",
    "    Y = np.random.normal(mean, std, (row, col, ch))\n",
    "    rician_noise = np.sqrt(X**2 + Y**2)\n",
    "    noisy_image = image + rician_noise\n",
    "    return noisy_image\n",
    "noisy_image_rician = add_rician_noise(image)\n",
    "\n",
    "noisy_image_normalized = noisy_image_rician / np.max(noisy_image_rician)\n",
    "plt.imshow(noisy_image_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(noisy_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Noisy Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur to remove noise\n",
    "blurred_image = cv2.GaussianBlur(noisy_image, (5, 5), 0)\n",
    "\n",
    "\n",
    "plt.imshow(blurred_image)\n",
    "plt.title('Blurred Image (Noise Removed)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99928434",
   "metadata": {},
   "source": [
    "# Fuzzy c means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "def fuzzy_c_means_clustering(data, n_clusters, m=2, max_iter=100, error=0.005):\n",
    "    \"\"\"\n",
    "    Perform Fuzzy C-Means clustering on the input data.\n",
    "\n",
    "    Parameters:\n",
    "        data (ndarray): Input data, where each row corresponds to a data point.\n",
    "        n_clusters (int): Number of clusters.\n",
    "        m (float, optional): Fuzzifier exponent. Defaults to 2.\n",
    "        max_iter (int, optional): Maximum number of iterations. Defaults to 100.\n",
    "        error (float, optional): Stopping criterion. Defaults to 0.005.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Cluster centers.\n",
    "        ndarray: Membership values of data points to each cluster.\n",
    "    \"\"\"\n",
    "    # Perform Fuzzy C-Means clustering\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data.T, n_clusters, m,\n",
    "                                                      error=error, maxiter=max_iter,\n",
    "                                                      init=None)\n",
    "    return cntr, u\n",
    "\n",
    "\n",
    "# Convert the noisy image to grayscale\n",
    "gray_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Reshape the grayscale image into a 1D array\n",
    "data = gray_image.reshape((-1, 1))\n",
    "\n",
    "# Define parameters for Fuzzy C-Means clustering\n",
    "n_clusters = 5\n",
    "max_iter = 100\n",
    "m = 2\n",
    "error = 0.005\n",
    "\n",
    "# Fuzzy C-Means clustering\n",
    "cluster_centers, membership_values = fuzzy_c_means_clustering(data, n_clusters, m, max_iter, error)\n",
    "\n",
    "# Get the clustered image\n",
    "clustered_image = np.uint8(np.round(cluster_centers[membership_values.argmax(axis=0)]))\n",
    "clustered_image = clustered_image.reshape(gray_image.shape)\n",
    "\n",
    "plt.imshow(clustered_image, cmap='gray')\n",
    "# plt.title('Fuzzy C means')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85522af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import cv2\n",
    "\n",
    "original_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\")\n",
    "segmented_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/resultimg/fcm.png\")\n",
    "\n",
    "# Resize segmented image to match original image dimensions\n",
    "segmented_img_resized = cv2.resize(segmented_img, (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "# Calculate PSNR value\n",
    "psnr_value = peak_signal_noise_ratio(original_img, segmented_img_resized)\n",
    "\n",
    "print(\"PSNR value:\", psnr_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, sqrt \n",
    "import cv2 \n",
    "import numpy as np \n",
    "\n",
    "def PSNR(original, compressed): \n",
    "    original_height, original_width, _ = original.shape\n",
    "    compressed = cv2.resize(compressed, (original_width, original_height))\n",
    "    \n",
    "    mse = np.mean((original - compressed) ** 2) \n",
    "    if mse == 0: \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "\n",
    "def main(): \n",
    "    original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\") \n",
    "    compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/resultimg/fcm.png\", 1) \n",
    "    value = PSNR(original, compressed) \n",
    "    print(f\"PSNR value is {value} dB\") \n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea732395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def psnr(original_img, compressed_img):\n",
    "    original_height, original_width, _ = original_img.shape\n",
    "    compressed_img = cv2.resize(compressed_img, (original_width, original_height))\n",
    "    \n",
    "    original_img = original_img.astype(np.float32)\n",
    "    compressed_img = compressed_img.astype(np.float32)\n",
    "    \n",
    "    mse = np.mean((original_img - compressed_img) ** 2)\n",
    "    \n",
    "    max_pixel = 255.0\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr_value = 10 * math.log10((max_pixel ** 2) / mse)\n",
    "    return psnr_value\n",
    "\n",
    "# Example usage:\n",
    "original_image = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\") \n",
    "compressed_image = cv2.imread(\"C:/Users/Admin/Desktop/datasets/resultimg/fcm.png\")\n",
    "\n",
    "psnr_value = psnr(original_image, compressed_image)\n",
    "print(\"PSNR value:\", psnr_value, \"dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adf71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def misclassification_error_rate(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Calculate misclassification error rate\n",
    "    intersection = cv2.bitwise_and(original_gray, segmented_mask_resized)\n",
    "    union = cv2.bitwise_or(original_gray, segmented_mask_resized)\n",
    "    misclassification_error_rate = 1.0 - np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    return misclassification_error_rate * 100\n",
    "\n",
    "\n",
    "# Calculate misclassification error rate\n",
    "error_rate = misclassification_error_rate(original_img, segmented_img)\n",
    "print(\"Misclassification Error Rate:\", error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b19c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def psnr(original_img, segmented_img):\n",
    "    # Resize segmented image to match the dimensions of the original image\n",
    "    segmented_img_resized = cv2.resize(segmented_img, (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "    # Ensure images are of type float\n",
    "    original_img = original_img.astype(float)\n",
    "    segmented_img_resized = segmented_img_resized.astype(float)\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = np.mean((original_img - segmented_img_resized) ** 2)\n",
    "\n",
    "    # Calculate maximum possible pixel value\n",
    "    max_pixel_value = np.max(original_img)\n",
    "\n",
    "    # Calculate PSNR\n",
    "    psnr_value = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
    "\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "psnr_value = psnr(original_img, segmented_img)\n",
    "print(\"PSNR:\", psnr_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Define positive and negative regions based on the segmented mask\n",
    "    positive_regions = original_gray > 0  # Regions with non-zero intensity in the original image\n",
    "    negative_regions = original_gray == 0  # Background regions in the original image\n",
    "    \n",
    "    # Count the number of pixels classified as positive or negative in the segmented mask\n",
    "    positive_pixels_count = cv2.countNonZero(segmented_mask_resized)\n",
    "    negative_pixels_count = segmented_mask_resized.size - positive_pixels_count\n",
    "    \n",
    "    # Count the number of true positives, true negatives, false positives, and false negatives\n",
    "    TP = np.sum(np.logical_and(positive_regions, segmented_mask_resized))\n",
    "    TN = np.sum(np.logical_and(negative_regions, np.logical_not(segmented_mask_resized)))\n",
    "    FP = positive_pixels_count - TP\n",
    "    FN = negative_pixels_count - TN\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(original_img, segmented_img)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_sensitivity(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Calculate True Positives (TP) and False Negatives (FN)\n",
    "    TP = np.sum(np.logical_and(original_gray > 0, segmented_mask_resized > 0))\n",
    "    FN = np.sum(np.logical_and(original_gray > 0, segmented_mask_resized == 0))\n",
    "    \n",
    "    # Calculate Sensitivity (Sen)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    \n",
    "    return sensitivity\n",
    "\n",
    "# Calculate Sensitivity\n",
    "sensitivity = calculate_sensitivity(original_img, segmented_img)\n",
    "print(\"Sensitivity (Sen):\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4974e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def psnr(img1, img2):\n",
    "#     mse = np.mean((img1 - img2) ** 2)\n",
    "#     if mse == 0:\n",
    "#         return float('inf')\n",
    "#     max_pixel = 255.0\n",
    "#     psnr_val = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "#     return psnr_val\n",
    "\n",
    "# # def psnr_segmented(original_img, segmented_img):\n",
    "# #     # Resize segmented image to match original image dimensions\n",
    "# #     segmented_img_resized = cv2.resize(segmented_img, (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "# #     segmented_regions = cv2.split(segmented_img_resized)\n",
    "# #     original_regions = cv2.split(original_img)\n",
    "# #     psnr_values = []\n",
    "# #     for seg_region, orig_region in zip(segmented_regions, original_regions):\n",
    "# #         psnr_val = psnr(seg_region, orig_region)\n",
    "# #         psnr_values.append(psnr_val)\n",
    "# #     return psnr_values\n",
    "\n",
    "# # Load original image and segmented image\n",
    "# original_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\")\n",
    "# segmented_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/fc1.png\")\n",
    "\n",
    "# # Compute PSNR for each segmented region\n",
    "# psnr_values = psnr_segmented(original_img, segmented_img)\n",
    "\n",
    "# # Print PSNR values for each segmented region\n",
    "# for i, psnr_val in enumerate(psnr_values):\n",
    "#     print(f\"PSNR for segmented region {i+1}: {psnr_val:.2f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clustered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136a267",
   "metadata": {},
   "source": [
    "# Fuzzy C Means clustering With KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ced1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifcm_image_segmentations(clustered_image, num_clusters=4, m=2, h=0.1, lamda=1.0, max_iters=100, error_threshold=1e-4):\n",
    "    num_samples, num_features = clustered_image.shape\n",
    "    cluster_centers = np.random.rand(num_clusters, num_features)\n",
    "    u = np.random.rand(num_samples, num_clusters)\n",
    "    v = np.random.rand(num_samples, num_clusters)\n",
    "    hesitancy = np.full((num_samples, num_clusters), h)\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        for j in range(num_clusters):\n",
    "            numerator = np.sum((u[:, j] ** m + (1 - v[:, j]) ** m)[:, np.newaxis] * clustered_image, axis=0)\n",
    "            denominator = np.sum((u[:, j] ** m + (1 - v[:, j]) ** m))\n",
    "            cluster_centers[j] = numerator / denominator\n",
    "        # ... (rest of your code)\n",
    "\n",
    "        # Initialize Lagrange multipliers\n",
    "        lagrange_multipliers = np.zeros((num_samples, num_clusters))\n",
    "\n",
    "        # Update membership degrees (u_ij) and Lagrange multipliers using Lagrange's method\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_clusters):\n",
    "                u_ij_star = np.exp(-np.linalg.norm(clustered_image[i] - cluster_centers[j]) ** 2 / lamda)\n",
    "                u_sum = np.sum(np.exp(-np.linalg.norm(clustered_image[i] - cluster_centers[k]) ** 2  / lamda) for k in range(num_clusters))\n",
    "                u[i, j] = u_ij_star / u_sum\n",
    "\n",
    "                # Calculate the Lagrange multiplier term\n",
    "                lagrange_term = lamda * np.sum(u[i, k] * np.log(u[i, k] / v[i, k]) for k in range(num_clusters))\n",
    "                lagrange_multipliers[i, j] = lagrange_term\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(u - v) < error_threshold:\n",
    "            break\n",
    "\n",
    "        v = u.copy()  # Update v with the current u\n",
    "    \n",
    "\n",
    "    # After clustering is complete, reshape the results back to the original shape\n",
    "    cluster_assignments = np.argmax(u, axis=1)\n",
    "    results = clustered_image.reshape(image.shape[:2])\n",
    "\n",
    "    return results, cluster_assignments, v\n",
    "\n",
    "result_images, cluster_assignments, non_membership_matrix = ifcm_image_segmentations(clustered_image, num_clusters=4, m=2, h=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebffd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results=result_image.reshape(resized_image.shape)\n",
    "# plt.subplot(142)\n",
    "plt.imshow(result_images, cmap='gray')\n",
    "print(result_images)\n",
    "# plt.title('Segmentation')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05298cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import cv2\n",
    "\n",
    "original_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\")\n",
    "segmented_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/resultimg/fcmkl.png\")\n",
    "\n",
    "# Resize segmented image to match original image dimensions\n",
    "segmented_img_resized = cv2.resize(segmented_img, (original_img.shape[1], original_img.shape[0]))\n",
    "\n",
    "# Calculate PSNR value\n",
    "psnr_value = peak_signal_noise_ratio(original_img, segmented_img_resized)\n",
    "\n",
    "print(\"PSNR value:\", psnr_value)\n",
    "\n",
    "\n",
    "def misclassification_error_rate(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Calculate misclassification error rate\n",
    "    intersection = cv2.bitwise_and(original_gray, segmented_mask_resized)\n",
    "    union = cv2.bitwise_or(original_gray, segmented_mask_resized)\n",
    "    misclassification_error_rate = 1.0 - np.sum(intersection) / np.sum(union)\n",
    "    \n",
    "    return misclassification_error_rate * 100\n",
    "\n",
    "\n",
    "\n",
    "# Calculate misclassification error rate\n",
    "error_rate = misclassification_error_rate(original_img, segmented_img)\n",
    "print(\"Misclassification Error Rate:\", error_rate)\n",
    "\n",
    "\n",
    "def calculate_accuracy(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Define positive and negative regions based on the segmented mask\n",
    "    positive_regions = original_gray > 0  # Regions with non-zero intensity in the original image\n",
    "    negative_regions = original_gray == 0  # Background regions in the original image\n",
    "    \n",
    "    # Count the number of pixels classified as positive or negative in the segmented mask\n",
    "    positive_pixels_count = cv2.countNonZero(segmented_mask_resized)\n",
    "    negative_pixels_count = segmented_mask_resized.size - positive_pixels_count\n",
    "    \n",
    "    # Count the number of true positives, true negatives, false positives, and false negatives\n",
    "    TP = np.sum(np.logical_and(positive_regions, segmented_mask_resized))\n",
    "    TN = np.sum(np.logical_and(negative_regions, np.logical_not(segmented_mask_resized)))\n",
    "    FP = positive_pixels_count - TP\n",
    "    FN = negative_pixels_count - TN\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(original_img, segmented_img)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "def calculate_sensitivity(original_img, segmented_img):\n",
    "    # Convert images to grayscale\n",
    "    original_gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "    segmented_gray = cv2.cvtColor(segmented_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the segmented image to obtain binary mask\n",
    "    _, segmented_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize segmented mask to match the dimensions of the original grayscale image\n",
    "    segmented_mask_resized = cv2.resize(segmented_mask, (original_gray.shape[1], original_gray.shape[0]))\n",
    "    \n",
    "    # Calculate True Positives (TP) and False Negatives (FN)\n",
    "    TP = np.sum(np.logical_and(original_gray > 0, segmented_mask_resized > 0))\n",
    "    FN = np.sum(np.logical_and(original_gray > 0, segmented_mask_resized == 0))\n",
    "    \n",
    "    # Calculate Sensitivity (Sen)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    \n",
    "    return sensitivity\n",
    "\n",
    "\n",
    "\n",
    "# Calculate Sensitivity\n",
    "sensitivity = calculate_sensitivity(original_img, segmented_img)\n",
    "print(\"Sensitivity (Sen):\", sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73335602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc1656a",
   "metadata": {},
   "source": [
    "# Picture Fuzzy C-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define kernel function (Gaussian kernel)\n",
    "def kernel_function(x1, x2, sigma=10):\n",
    "    return np.exp(-np.sum((x1 - x2)**2) / ( (sigma**2)))\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 5\n",
    "max_iterations = 2\n",
    "tolerance = 0.001\n",
    "m = 2\n",
    "alpha = 10\n",
    "\n",
    "# Initialize cluster centers randomly\n",
    "centers = np.random.rand(n_clusters, data.shape[1])\n",
    "\n",
    "# Initialize membership matrix randomly\n",
    "membership_matrix = np.random.rand(n_clusters, len(data))\n",
    "\n",
    "# Fuzzy C-Means clustering\n",
    "for _ in range(max_iterations):\n",
    "    # Update eta and xi parameters\n",
    "    for i in range(len(data)):\n",
    "        for j in range(n_clusters):\n",
    "            # Initialize eta_ij and xi_ij\n",
    "            xi_ij = 1\n",
    "            eta_ij = 1\n",
    "\n",
    "            # Compute xi_ij\n",
    "            xi_ij = 1 - (membership_matrix[j, i] + eta_ij) - ((1 - (membership_matrix[j, i] + eta_ij)) ** alpha) ** (1 / alpha)\n",
    "\n",
    "            # Compute eta_ij\n",
    "            denominator_eta = np.sum((membership_matrix[j, i] / membership_matrix[k, i]) * ((np.linalg.norm(data[i] - centers[j]) ** 2) / (np.linalg.norm(data[i] - centers[k]) ** 2)) ** (1 / (m - 1)) for k in range(n_clusters))\n",
    "            eta_ij = 1 - xi_ij - ((n_clusters - 1) / n_clusters) * np.sum(xi_ij for k in range(n_clusters)) / denominator_eta\n",
    "\n",
    "            # Update membership matrix\n",
    "            numerator_membership = (1 - eta_ij - xi_ij)\n",
    "            denominator_membership = np.sum(((np.linalg.norm(data[i] - centers[j]) ** 2) / (np.linalg.norm(data[i] - centers[k]) ** 2)) ** (1 / (m - 1)) for k in range(n_clusters))\n",
    "            membership_matrix[j, i] = numerator_membership / denominator_membership\n",
    "\n",
    "    # Update cluster centers\n",
    "    for j in range(n_clusters):\n",
    "        numerator_centers = np.sum((membership_matrix[j, i] / (1 - eta_ij - xi_ij)) ** m * data[i] for i in range(len(data)))\n",
    "        denominator_centers = np.sum((membership_matrix[j, i] / (1 - eta_ij - xi_ij)) ** m for i in range(len(data)))\n",
    "        centers[j] = numerator_centers / denominator_centers\n",
    "\n",
    "\n",
    "# Extract cluster labels\n",
    "cluster_labels = np.argmax(membership_matrix, axis=0)\n",
    "\n",
    "# Reshape the cluster labels back to the shape of the original image\n",
    "clustered_images = cluster_labels.reshape(result_images.shape)\n",
    "\n",
    "# Display the clustered image\n",
    "plt.imshow(clustered_images, cmap='gray')\n",
    "plt.title('Picture Fuzzy C-Means Clustering')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf4a8a",
   "metadata": {},
   "source": [
    "# kernel fuzzy clustering based on picture fuzzy sets and KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98be39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define kernel function (Gaussian kernel)\n",
    "def kernel_function(x1, x2, sigma=10):\n",
    "    return np.exp(-np.sum((x1 - x2)**2) / (2 * (sigma**2)))\n",
    "\n",
    "# Define the robust semi-supervised picture fuzzy clustering function\n",
    "def picture_fuzzy_clustering(data_points, n_clusters, max_iterations, m, alpha, gamma, sigma):\n",
    "    n_points = len(data_points)\n",
    "    n_features = data_points.shape[1]\n",
    "\n",
    "    # Initialize cluster centers randomly\n",
    "    centers = np.random.rand(n_clusters, n_features)\n",
    "\n",
    "    # Initialize membership matrix randomly\n",
    "    membership_matrix = np.random.rand(n_clusters, n_points)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Update membership matrix\n",
    "        membership_matrix, eta_matrix, xi_matrix = update_membership_matrix(data_points, centers, membership_matrix, m, alpha, gamma)\n",
    "\n",
    "        # Update cluster centers\n",
    "        centers = update_cluster_centers(data_points, membership_matrix, eta_matrix, xi_matrix, sigma)\n",
    "\n",
    "    return centers, membership_matrix\n",
    "\n",
    "# Define function to update membership matrix, eta, and xi\n",
    "def update_membership_matrix(data_points, centers, membership_matrix, m, alpha, gamma):\n",
    "    n_clusters = centers.shape[0]\n",
    "    n_points = len(data_points)\n",
    "\n",
    "    updated_membership_matrix = np.zeros_like(membership_matrix)\n",
    "    eta_matrix = np.zeros_like(membership_matrix)\n",
    "    xi_matrix = np.zeros_like(membership_matrix)\n",
    "\n",
    "    for i in range(n_points):\n",
    "        for j in range(n_clusters):\n",
    "            # Calculate pi_ij\n",
    "            pi_ij = np.mean(membership_matrix[j] * (2 - xi_matrix))\n",
    "\n",
    "            # Calculate mu_ij\n",
    "            mu_numerator = pi_ij * np.exp(-(1 - data_points[i] - centers[j]) / gamma)\n",
    "            mu_denominator = np.sum([np.mean(membership_matrix[l] * (2 - xi_matrix)) * np.exp(-(1 - data_points[i] - centers[l]) / gamma) for l in range(n_clusters)])\n",
    "            mu_ij = mu_numerator / mu_denominator * (1 / (2 - xi_matrix[j, i]))\n",
    "\n",
    "            # Calculate k(x_j, v_i)\n",
    "            k_xj_vi = np.exp(-np.linalg.norm(data_points[i] - centers[j])**2 / (2 * (sigma**2)))\n",
    "\n",
    "            # Calculate eta_ij\n",
    "            exp_xi_ij = np.exp(-xi_matrix[j, i])\n",
    "            sum_exp_xi_lj = np.sum(np.exp(-xi_matrix[l, i]) for l in range(n_clusters))\n",
    "            eta_matrix[j, i] = exp_xi_ij / sum_exp_xi_lj * (1 - np.sum(xi_matrix[:, i]) / n_clusters)\n",
    "\n",
    "            # Calculate xi_ij\n",
    "            u_ij = updated_membership_matrix[j, i]\n",
    "            xi_matrix[j, i] = 1 - (u_ij + eta_matrix[j, i]) - (1 - (u_ij + eta_matrix[j, i])**alpha)**(1/alpha)\n",
    "\n",
    "            # Update membership matrix elements\n",
    "            updated_membership_matrix[j, i] = mu_ij * (2 - xi_matrix[j, i]) * (1 - k_xj_vi)\n",
    "\n",
    "    return updated_membership_matrix, eta_matrix, xi_matrix\n",
    "\n",
    "\n",
    "# Define function to update cluster centers\n",
    "def update_cluster_centers(data_points, membership_matrix, eta_matrix, xi_matrix, sigma):\n",
    "    n_clusters = membership_matrix.shape[0]\n",
    "    n_points = len(data_points)\n",
    "    n_features = data_points.shape[1]\n",
    "\n",
    "    centers = np.zeros((n_clusters, n_features))\n",
    "\n",
    "    for j in range(n_clusters):\n",
    "        numerator = np.zeros(n_features)\n",
    "        denominator = 0\n",
    "\n",
    "        for i in range(n_points):\n",
    "            mu_xi = membership_matrix[j, i] * (2 - xi_matrix[j, i])\n",
    "            k_xj_vi = np.exp(-np.linalg.norm(data_points[i] - centers[j])**2 / (2 * (sigma**2)))\n",
    "\n",
    "            numerator += mu_xi * k_xj_vi * data_points[i]\n",
    "            denominator += mu_xi * k_xj_vi\n",
    "\n",
    "        centers[j] = numerator / denominator\n",
    "\n",
    "    return centers\n",
    "\n",
    "# Load the image\n",
    "# image = cv2.imread('/content/drive/MyDrive/y0.jpg')\n",
    "# gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Reshape the image into a 1D array of data points\n",
    "data_points = clustered_images.reshape((-1, 1)).astype(np.float32)\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 2\n",
    "max_iterations = 10\n",
    "m = 3\n",
    "alpha = 1\n",
    "gamma = 1\n",
    "sigma = 10\n",
    "\n",
    "# Perform robust semi-supervised picture fuzzy clustering\n",
    "centers, membership_matrix = picture_fuzzy_clustering(data_points, n_clusters, max_iterations, m, alpha, gamma, sigma)\n",
    "\n",
    "# Reshape the cluster labels back to the shape of the original image\n",
    "cluster_labels = np.argmax(membership_matrix, axis=0)\n",
    "clustere_img= cluster_labels.reshape(clustered_images.shape)\n",
    "\n",
    "# Display the clustered image\n",
    "plt.imshow(clustere_img, cmap='gray')\n",
    "plt.title('Robust Semi-Supervised Picture Fuzzy Clustering')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skfuzzy import cmeans\n",
    "\n",
    "# Load the input image\n",
    "image_path = \"C:/Users/Admin/Desktop/datasets/lung.jpg\"\n",
    "image = io.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = rgb2gray(image)\n",
    "\n",
    "# Apply Otsu's thresholding to obtain a binary image\n",
    "threshold_value = threshold_otsu(gray_image)\n",
    "binary_image = gray_image > threshold_value\n",
    "\n",
    "# Flatten the binary image\n",
    "data = binary_image.flatten()\n",
    "\n",
    "# Perform Fuzzy C-means clustering\n",
    "centers, u, _, _, _, _, _ = cmeans(data.reshape(1, -1), c=2, m=2, error=0.005, maxiter=1000, seed=0)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "\n",
    "# Reshape the cluster labels to the original image shape\n",
    "cluster_labels = cluster_labels.reshape(binary_image.shape)\n",
    "\n",
    "# Display the original image and the clustered image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(binary_image, cmap='gray')\n",
    "plt.title('Binary Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cluster_labels, cmap='gray')\n",
    "plt.title('Clustered Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Assuming you have ground truth labels for the image\n",
    "# Create ground truth labels (for demonstration purposes)\n",
    "ground_truth_labels = np.zeros_like(cluster_labels)\n",
    "ground_truth_labels[50:150, 50:150] = 1  # Assuming the object is located in this region\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_labels.flatten(), cluster_labels.flatten())\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "image_path = \"C:/Users/Admin/Desktop/datasets/lung.jpg\"\n",
    "image = io.imread(image_path)\n",
    "\n",
    "# Assuming the lung region is located in a specific area of the image\n",
    "lung_region = np.zeros_like(image)\n",
    "# lung_region[100:300, 200:400] = 1  # Assuming the lung region is located in this region\n",
    "\n",
    "# Display the lung region\n",
    "plt.imshow(lung_region, cmap='gray')\n",
    "plt.title('Ground Truth Labels (Lung Region)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skfuzzy import cmeans\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=5):\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image\n",
    "\n",
    "# Load the input image\n",
    "image_path = \"C:/Users/Admin/Desktop/datasets/lung.jpg\"\n",
    "image = io.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = rgb2gray(image)\n",
    "\n",
    "# Apply Otsu's thresholding to obtain a binary image\n",
    "threshold_value = threshold_otsu(gray_image)\n",
    "binary_image = gray_image > threshold_value\n",
    "\n",
    "# Add Gaussian noise to the original image\n",
    "noisy_image = add_gaussian_noise(image)\n",
    "\n",
    "# Convert the noisy image to grayscale\n",
    "noisy_gray_image = rgb2gray(noisy_image)\n",
    "\n",
    "# Apply Otsu's thresholding to obtain a binary image from the noisy image\n",
    "threshold_value_noisy = threshold_otsu(noisy_gray_image)\n",
    "binary_image_noisy = noisy_gray_image > threshold_value_noisy\n",
    "\n",
    "# Flatten the binary image from the noisy image\n",
    "data_noisy = binary_image_noisy.flatten()\n",
    "\n",
    "# Perform Fuzzy C-means clustering on the noisy image\n",
    "centers_noisy, u_noisy, _, _, _, _, _ = cmeans(data_noisy.reshape(1, -1), c=2, m=2, error=0.005, maxiter=1000, seed=0)\n",
    "\n",
    "# Get the cluster labels for the noisy image\n",
    "cluster_labels_noisy = np.argmax(u_noisy, axis=0)\n",
    "\n",
    "# Reshape the cluster labels to the original image shape for the noisy image\n",
    "cluster_labels_noisy = cluster_labels_noisy.reshape(binary_image_noisy.shape)\n",
    "\n",
    "# Display the original image, noisy image, and the clustered image of the noisy image\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noisy_image)\n",
    "plt.title('Noisy Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cluster_labels_noisy, cmap='gray')\n",
    "plt.title('Clustered Image (Noisy)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate artificial ground truth labels (for demonstration purposes)\n",
    "ground_truth_labels = np.zeros_like(cluster_labels_noisy)\n",
    "ground_truth_labels[50:150, 50:150] = 1  # Assuming the object is located in this region\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_labels.flatten(), cluster_labels_noisy.flatten())\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ee0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ff851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8638d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4a099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the original image\n",
    "original_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/lung.jpg\")\n",
    "\n",
    "# Preprocessing (if needed)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Thresholding: Simple binary segmentation (lung vs. background)\n",
    "_, binary_mask = cv2.threshold(gray_img, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "\n",
    "# Post-processing (if needed)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_img[:, :, ::-1])  # Convert BGR to RGB for display\n",
    "plt.title('Original Image')\n",
    "print(original_img.shape)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daadcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(binary_mask, cmap='gray')\n",
    "# print(binary_mask.shape)\n",
    "# print(binary_mask)\n",
    "# plt.title('Ground Truth Segmentation (Binary)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, std=3):\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb79705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add Gaussian noise to the image\n",
    "noisy_image = add_gaussian_noise(binary_mask)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(noisy_image, cv2.COLOR_BGR2RGB))\n",
    "print(noisy_image.shape)\n",
    "# plt.title('Gaussian noisy_image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur to remove noise\n",
    "blurred_image = cv2.GaussianBlur(noisy_image, (5, 5), 0)\n",
    "\n",
    "\n",
    "plt.imshow(blurred_image,cmap='gray')\n",
    "# plt.title('Blurred Image (Noise Removed)')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d13b9",
   "metadata": {},
   "source": [
    "# Fuzzy c means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCM:\n",
    "    def __init__(self, n_clusters=2, max_iter=100, m=2, error=1e-5, random_state=None):\n",
    "        self.u, self.centers = None, None\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.m = m\n",
    "        self.error = error\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "      n_samples = X.shape[0]\n",
    "      if self.random_state is not None:\n",
    "        np.random.seed(self.random_state)\n",
    "      u = np.random.rand(n_samples, self.n_clusters)\n",
    "      u = u / np.sum(u, axis=1, keepdims=True)\n",
    "\n",
    "      for _ in range(self.max_iter):\n",
    "        u_old = u.copy()\n",
    "        centers = self._calculate_centers(X, u)\n",
    "        u = self._update_membership(X, centers)\n",
    "        if np.linalg.norm(u - u_old.reshape(u.shape)) < self.error:\n",
    "            break\n",
    "\n",
    "      self.u = u\n",
    "      self.centers = centers\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_centers(self, X, u):\n",
    "        um = u ** self.m\n",
    "        centers = um.T.dot(X) / np.sum(um, axis=0, keepdims=True).T\n",
    "        return centers\n",
    "\n",
    "    def _update_membership(self, X, centers):\n",
    "        dist = np.linalg.norm(X[:, np.newaxis] - centers, axis=2)\n",
    "        dist = np.fmax(dist, np.finfo(np.float64).eps)\n",
    "        u = dist[:, :, np.newaxis] / dist[:, :, np.newaxis].sum(axis=1, keepdims=True)\n",
    "        u = u ** (2 / (self.m - 1))\n",
    "        u = u / u.sum(axis=1, keepdims=True)\n",
    "        return u\n",
    "\n",
    "    def predict(self, X):\n",
    "        dist = np.linalg.norm(X[:, np.newaxis] - self.centers, axis=2)\n",
    "        return np.argmin(dist, axis=1)\n",
    "    \n",
    "  # Convert the input image to 2D array and normalize\n",
    "image_2d = blurred_image.reshape((-1, 1)).astype(float) / 255.0\n",
    "\n",
    "# Perform Fuzzy C-means clustering\n",
    "n_clusters = 5  # Number of clusters\n",
    "max_iter = 100  # Maximum number of iterations\n",
    "fcm = FCM(n_clusters=n_clusters, max_iter=max_iter)\n",
    "fcm.fit(image_2d)\n",
    "\n",
    "# Predict cluster labels\n",
    "cluster_labels = fcm.predict(image_2d)\n",
    "\n",
    "# Reshape cluster labels to the shape of the original image\n",
    "cluster_labels_2d = cluster_labels.reshape(blurred_image.shape[0], blurred_image.shape[1])\n",
    "\n",
    "plt.imshow(cluster_labels_2d, cmap='gray')\n",
    "print(cluster_labels_2d)\n",
    "# plt.title('Segmented Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46779c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (cluster_labels_2d.shape[1], cluster_labels_2d.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), cluster_labels_2d.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c1.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n",
    "\n",
    "\n",
    "\n",
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c1.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4362556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (cluster_labels_2d.shape[1], cluster_labels_2d.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), cluster_labels_2d.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c1.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c1.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bde307",
   "metadata": {},
   "source": [
    "# Fuzzy c means clustering with KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def likl_segmentation(blurred_image, num_clusters=4, m=2, lamda=1.0, max_iters=100, error_threshold=1e-4):\n",
    "    # Load the image\n",
    "    image = blurred_image.astype(np.float32)\n",
    "    \n",
    "    # Convert the image to float32\n",
    "    image = np.float32(image)\n",
    "    \n",
    "    # Initialize cluster centers randomly\n",
    "    num_samples, num_features = image.shape\n",
    "    cluster_centers = np.random.rand(num_clusters, num_features)\n",
    "    \n",
    "    # Initialize membership degrees randomly\n",
    "    u = np.random.rand(num_samples, num_clusters)\n",
    "    \n",
    "    # Initialize Lagrange multipliers\n",
    "    lagrange_multipliers = np.zeros((num_samples, num_clusters))\n",
    "    \n",
    "    u_old = np.zeros_like(u)  # Initialize u_old outside the loop\n",
    "    \n",
    "    for iteration in range(max_iters):\n",
    "        # Update cluster centers\n",
    "        for j in range(num_clusters):\n",
    "            numerator = np.sum((u[:, j] ** m)[:, np.newaxis] * image, axis=0)\n",
    "            denominator = np.sum(u[:, j] ** m)\n",
    "            cluster_centers[j] = numerator / denominator\n",
    "        \n",
    "        # Update membership degrees and Lagrange multipliers\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_clusters):\n",
    "                u_ij_star = np.exp(-np.linalg.norm(image[i] - cluster_centers[j]) ** 2 / lamda)\n",
    "                u_sum = np.sum(np.exp(-np.linalg.norm(image[i] - cluster_centers[k]) ** 2 / lamda) for k in range(num_clusters))\n",
    "                u[i, j] = u_ij_star / u_sum\n",
    "                \n",
    "                # Calculate the Lagrange multiplier term\n",
    "                lagrange_term = lamda * np.sum(u[i, k] * np.log(u[i, k]) for k in range(num_clusters))\n",
    "                lagrange_multipliers[i, j] = lagrange_term\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(u - u_old) < error_threshold:\n",
    "            break\n",
    "        \n",
    "        u_old = u.copy()  # Update u_old with the current u\n",
    "    \n",
    "    # After clustering is complete, reshape the results back to the original shape\n",
    "    cluster_assignments = np.argmax(u, axis=1)\n",
    "    results = image.reshape((num_samples, num_features))  # Fix the reshape\n",
    "    \n",
    "    return results\n",
    "\n",
    "# segmented_image = likl_segmentation(noisy_image)\n",
    "# Perform further processing or visualization with the segmented_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segmented_image = likl_segmentation(blurred_image)\n",
    "\n",
    "# Display the segmented image\n",
    "plt.imshow(segmented_image, cmap='gray')  # You can use any colormap you prefer\n",
    "# plt.title('Segmented Image')\n",
    "plt.axis('off')\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmented_image.shape)\n",
    "print(segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (segmented_image.shape[1], segmented_image.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), segmented_image.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c2.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n",
    "\n",
    "\n",
    "\n",
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c2.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40d911f",
   "metadata": {},
   "source": [
    "# Picture fuzzy c means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blurred_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ceed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "class FCMCustom:\n",
    "    def __init__(self, n_clusters=2, max_iter=100, sigma=1.0, alpha=1.0, gamma=1.0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.u = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        centers = np.random.rand(self.n_clusters, n_features)\n",
    "        eta = np.random.rand(n_samples, self.n_clusters)\n",
    "        xi = np.random.rand(n_samples, self.n_clusters)\n",
    "        self.u = np.random.rand(n_samples, self.n_clusters)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            w = self._calculate_w(X)\n",
    "            eta = self._calculate_eta(xi)\n",
    "            xi = self._calculate_xi(X, centers, eta)\n",
    "            centers = self._calculate_centers(X, w)\n",
    "\n",
    "        self.u = self._calculate_u(X, centers, eta, xi, w)\n",
    "        self.centers = centers\n",
    "\n",
    "    def _calculate_w(self, X):\n",
    "        c = self.n_clusters\n",
    "        n_samples = X.shape[0]\n",
    "        w = np.zeros((n_samples, c))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            for j in range(c):\n",
    "                w[i, j] = np.exp(-np.sum((self.u[:, j] - self.u[i, j]) ** 2) / self.sigma)\n",
    "            w[i] /= np.sum(w[i])\n",
    "        return w\n",
    "\n",
    "    def _calculate_eta(self, xi):\n",
    "        return (xi ** 2) / (self.n_clusters * (xi + 2 * xi))\n",
    "\n",
    "    def _calculate_xi(self, X, centers, eta):\n",
    "        alpha = self.alpha\n",
    "        xi = np.zeros_like(eta)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(self.n_clusters):\n",
    "                xi[i, j] = 1 - (self.u[i, j] + eta[i, j]) - (1 - (self.u[i, j] + eta[i, j]) ** alpha) ** (1 / alpha)\n",
    "        return xi\n",
    "\n",
    "    def _calculate_centers(self, X, w):\n",
    "        c = self.n_clusters\n",
    "        centers = np.zeros((c, X.shape[1]))\n",
    "        for j in range(c):\n",
    "            denominator = np.sum(w[:, j])\n",
    "            if denominator != 0:  # Avoid division by zero\n",
    "                numerator = np.sum((w[:, j][:, np.newaxis] * X), axis=0)\n",
    "                centers[j] = numerator / denominator\n",
    "            else:\n",
    "                centers[j] = 0  # Set centers to zero if any denominator is zero\n",
    "        return centers\n",
    "\n",
    "    def _calculate_u(self, X, centers, eta, xi, w):\n",
    "      n_samples = X.shape[0]\n",
    "      c = self.n_clusters\n",
    "      u = np.zeros((n_samples, c))\n",
    "      for i in range(n_samples):\n",
    "        for j in range(c):\n",
    "            denominator = 1 - eta[i, j] - xi[i, j]\n",
    "            if not np.isclose(denominator, 0):  # Avoid division by zero\n",
    "                numerator = w[i, j] * np.exp(-np.sum((X[i] - centers[j]) ** 2))\n",
    "                u[i, j] = numerator / denominator\n",
    "            else:\n",
    "                u[i, j] = 0  # Set membership to zero if any denominator is close to zero\n",
    "        u[i] /= np.sum(u[i])\n",
    "      return u\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        dist = np.linalg.norm(X[:, np.newaxis] - self.centers, axis=2)\n",
    "        return np.argmin(dist, axis=1)\n",
    "\n",
    "# Read the original image\n",
    "image_path = \"C:/Users/Admin/Desktop/datasets/Ground_Img/dam.png\"\n",
    "original_image = io.imread(image_path)\n",
    "\n",
    "# Reshape the image data to a 2D array\n",
    "height, width, channels = original_image.shape\n",
    "image_2d = original_image.reshape((height * width, channels))\n",
    "\n",
    "# Normalize the image data\n",
    "image_2d = image_2d.astype(float) / 255.0\n",
    "\n",
    "# Perform Fuzzy C-means clustering\n",
    "n_clusters = 2  # Number of clusters\n",
    "max_iter = 1  # Maximum number of iterations\n",
    "sigma = 70  # Sigma parameter\n",
    "alpha = 1.0  # Alpha parameter\n",
    "gamma = 1.0  # Gamma parameter\n",
    "fcm_custom = FCMCustom(n_clusters=n_clusters, max_iter=max_iter, sigma=sigma, alpha=alpha, gamma=gamma)\n",
    "fcm_custom.fit(image_2d)\n",
    "\n",
    "# Predict cluster labels\n",
    "cluster_labels = fcm_custom.predict(image_2d)\n",
    "\n",
    "# Reshape cluster labels to the shape of the original image\n",
    "cluster_labels_2 = cluster_labels.reshape((height, width))\n",
    "\n",
    "# Plot the segmented image\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cluster_labels_2, cmap='gray')\n",
    "#Picture fuzzy c means clusturing\n",
    "print(original_image.shape)\n",
    "print(cluster_labels_2.shape)\n",
    "plt.title(\" Picture fuzzy c means clusturing\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(original_image)\n",
    "# plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cluster_labels_2, cmap='gray')\n",
    "#Picture fuzzy c means clusturing\n",
    "print(original_image.shape)\n",
    "print(cluster_labels_2.shape)\n",
    "# plt.title(\" Picture fuzzy c means clusturing\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d38208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (cluster_labels_2.shape[1], cluster_labels_2.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), cluster_labels_2.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c4.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n",
    "\n",
    "\n",
    "\n",
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c4.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487ba86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4d5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc775f7",
   "metadata": {},
   "source": [
    "# kernel fuzzy clustering based on picture fuzzy sets and KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define kernel function (Gaussian kernel)\n",
    "def kernel_function(x1, x2, sigma=1):\n",
    "    return np.exp(-np.sum((x1 - x2)**2) / (2 * (sigma**2)))\n",
    "\n",
    "# Define the robust semi-supervised picture fuzzy clustering function\n",
    "def picture_fuzzy_clustering(data_points, n_clusters, max_iterations, m, alpha, gamma, sigma):\n",
    "    n_points = len(data_points)\n",
    "    n_features = data_points.shape[1]\n",
    "\n",
    "    # Initialize cluster centers randomly\n",
    "    centers = np.random.rand(n_clusters, n_features)\n",
    "\n",
    "    # Initialize membership matrix randomly\n",
    "    membership_matrix = np.random.rand(n_clusters, n_points)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Update membership matrix\n",
    "        membership_matrix, eta_matrix, xi_matrix = update_membership_matrix(data_points, centers, membership_matrix, m, alpha, gamma)\n",
    "\n",
    "        # Update cluster centers\n",
    "        centers = update_cluster_centers(data_points, membership_matrix, eta_matrix, xi_matrix, sigma)\n",
    "\n",
    "    return centers, membership_matrix\n",
    "\n",
    "# Define function to update membership matrix, eta, and xi\n",
    "def update_membership_matrix(data_points, centers, membership_matrix, m, alpha, gamma):\n",
    "    n_clusters = centers.shape[0]\n",
    "    n_points = len(data_points)\n",
    "\n",
    "    updated_membership_matrix = np.zeros_like(membership_matrix)\n",
    "    eta_matrix = np.zeros_like(membership_matrix)\n",
    "    xi_matrix = np.zeros_like(membership_matrix)\n",
    "\n",
    "    for i in range(n_points):\n",
    "        for j in range(n_clusters):\n",
    "            # Calculate pi_ij\n",
    "            pi_ij = np.mean(membership_matrix[j] * (2 - xi_matrix))\n",
    "\n",
    "            # Calculate mu_ij\n",
    "            mu_numerator = pi_ij * np.exp(-(1 - data_points[i] - centers[j]) / gamma)\n",
    "            mu_denominator = np.sum([np.mean(membership_matrix[l] * (2 - xi_matrix)) * np.exp(-(1 - data_points[i] - centers[l]) / gamma) for l in range(n_clusters)])\n",
    "            mu_ij = mu_numerator / mu_denominator * (1 / (2 - xi_matrix[j, i]))\n",
    "\n",
    "            # Calculate k(x_j, v_i)\n",
    "            k_xj_vi = np.exp(-np.linalg.norm(data_points[i] - centers[j])**2 / (2 * (sigma**2)))\n",
    "\n",
    "            # Calculate eta_ij\n",
    "            exp_xi_ij = np.exp(-xi_matrix[j, i])\n",
    "            sum_exp_xi_lj = np.sum(np.exp(-xi_matrix[l, i]) for l in range(n_clusters))\n",
    "            eta_matrix[j, i] = exp_xi_ij / sum_exp_xi_lj * (1 - np.sum(xi_matrix[:, i]) / n_clusters)\n",
    "\n",
    "            # Calculate xi_ij\n",
    "            u_ij = updated_membership_matrix[j, i]\n",
    "            xi_matrix[j, i] = 1 - (u_ij + eta_matrix[j, i]) - (1 - (u_ij + eta_matrix[j, i])**alpha)**(1/alpha)\n",
    "\n",
    "            # Update membership matrix elements\n",
    "            updated_membership_matrix[j, i] = mu_ij * (2 - xi_matrix[j, i]) * (1 - k_xj_vi)\n",
    "\n",
    "    return updated_membership_matrix, eta_matrix, xi_matrix\n",
    "\n",
    "\n",
    "# Define function to update cluster centers\n",
    "def update_cluster_centers(data_points, membership_matrix, eta_matrix, xi_matrix, sigma):\n",
    "    n_clusters = membership_matrix.shape[0]\n",
    "    n_points = len(data_points)\n",
    "    n_features = data_points.shape[1]\n",
    "\n",
    "    centers = np.zeros((n_clusters, n_features))\n",
    "\n",
    "    for j in range(n_clusters):\n",
    "        numerator = np.zeros(n_features)\n",
    "        denominator = 0\n",
    "\n",
    "        for i in range(n_points):\n",
    "            mu_xi = membership_matrix[j, i] * (2 - xi_matrix[j, i])\n",
    "            k_xj_vi = np.exp(-np.linalg.norm(data_points[i] - centers[j])**2 / (2 * (sigma**2)))\n",
    "\n",
    "            numerator += mu_xi * k_xj_vi * data_points[i]\n",
    "            denominator += mu_xi * k_xj_vi\n",
    "\n",
    "        centers[j] = numerator / denominator\n",
    "\n",
    "    return centers\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('C:/Users/Admin/Desktop/datasets/Ground_Img/dam.png')\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(gray_image.shape)\n",
    "\n",
    "# Reshape the image into a 1D array of data points\n",
    "data_points = gray_image.reshape((-1, 1)).astype(np.float32)\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 2\n",
    "max_iterations = 1\n",
    "m = 3\n",
    "alpha = 1\n",
    "gamma = 1\n",
    "sigma = 1\n",
    "\n",
    "# Perform robust semi-supervised picture fuzzy clustering\n",
    "centers, membership_matrix = picture_fuzzy_clustering(data_points, n_clusters, max_iterations, m, alpha, gamma, sigma)\n",
    "\n",
    "# Reshape the cluster labels back to the shape of the original image\n",
    "cluster_labels = np.argmax(membership_matrix, axis=0)\n",
    "clustered_image = cluster_labels.reshape(gray_image.shape)\n",
    "\n",
    "# Display the clustered image\n",
    "plt.imshow(clustered_image, cmap='gray')\n",
    "# plt.title('Robust Semi-Supervised Picture Fuzzy Clustering')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58143b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (clustered_image.shape[1], clustered_image.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), clustered_image.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c5.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n",
    "\n",
    "\n",
    "\n",
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c5.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be2dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac3d16bc",
   "metadata": {},
   "source": [
    "# proposed work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "# Define kernel function (Gaussian kernel)\n",
    "def kernel_function(x1, x2, sigma=70):\n",
    "    return np.exp(-np.sum((x1 - x2)**2) / ( (sigma**2)))\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('C:/Users/Admin/Desktop/datasets/Ground_Img/dam.png')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Reshape the image into a 1D array of data points\n",
    "data_points = gray_image.reshape((-1, 1)).astype(np.float32)\n",
    "\n",
    "# Define parameters\n",
    "n_clusters = 2\n",
    "max_iterations = 2\n",
    "tolerance = 0.001\n",
    "m = 2\n",
    "alpha = 10\n",
    "lambda_val = 10\n",
    "\n",
    "# Initialize cluster centers randomly\n",
    "centers = np.random.rand(n_clusters, data_points.shape[1])\n",
    "\n",
    "# Initialize membership matrix randomly\n",
    "membership_matrix = np.random.rand(n_clusters, len(data_points))\n",
    "\n",
    "# Fuzzy C-Means clustering\n",
    "for _ in range(max_iterations):\n",
    "    # Compute distance matrix (using Gaussian kernel)\n",
    "    distance_matrix = np.zeros((n_clusters, len(data_points)))\n",
    "    for j in range(n_clusters):\n",
    "        for i in range(len(data_points)):\n",
    "            distance_matrix[j, i] = kernel_function(data_points[i], centers[j])\n",
    "\n",
    "    # Update membership matrix\n",
    "    for j in range(n_clusters):\n",
    "        for i in range(len(data_points)):\n",
    "            numerator = np.exp((-lambda_val + 2 * (1 + alpha) * (1 - distance_matrix[j, i])) * (alpha * np.sum(distance_matrix[:, i] * membership_matrix[:, j]) - membership_matrix[j, i]))\n",
    "            denominator = np.sum([np.exp((-lambda_val + 2 * (1 + alpha) * (1 - distance_matrix[k, i])) * (alpha * np.sum(distance_matrix[:, i] * membership_matrix[:, k]) - membership_matrix[k, i])) for k in range(n_clusters)])\n",
    "            membership_matrix[j, i] = numerator / denominator\n",
    "\n",
    "    # Update cluster centers\n",
    "    for j in range(n_clusters):\n",
    "        numerator = np.sum([(membership_matrix[j, i] * kernel_function(data_points[i], centers[j]) * data_points[i]) + (alpha * (membership_matrix[j, i] - distance_matrix[j, i]) ** 2 * data_points[i]) for i in range(len(data_points))], axis=0)\n",
    "        denominator = np.sum([membership_matrix[j, i] * kernel_function(data_points[i], centers[j]) + (alpha * (membership_matrix[j, i] - distance_matrix[j, i]) ** 2) for i in range(len(data_points))])\n",
    "        centers[j] = numerator / denominator\n",
    "\n",
    "# Extract cluster labels\n",
    "cluster_labels = np.argmax(membership_matrix, axis=0)\n",
    "\n",
    "# Reshape the cluster labels back to the shape of the original image\n",
    "clustered_images = cluster_labels.reshape(gray_image.shape)\n",
    "\n",
    "# Display the clustered image\n",
    "plt.imshow(clustered_images, cmap='gray')\n",
    "print(clustered_images)\n",
    "# plt.title('Fuzzy C-Means Clustering')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(clustered_images, cmap='gray')\n",
    "# print(clustered_images)\n",
    "# # plt.title('Fuzzy C-Means Clustering')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcddc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Load the ground truth input image\n",
    "ground_truth_img = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize the ground truth image to match the shape of cluster_membership_image\n",
    "ground_truth_img = cv2.resize(ground_truth_img, (clustered_images.shape[1], clustered_images.shape[0]))\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(ground_truth_img.flatten(), clustered_images.flatten())\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# Calculate true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) from the confusion matrix\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "TP = conf_matrix[1, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Calculate sensitivity (true positive rate or recall)\n",
    "sensitivity = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "print(\"TP=\",TP)\n",
    "print('TN=',TN)\n",
    "print('FN=',FN)\n",
    "print('FP=',FP)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "from math import log10, sqrt \n",
    " \n",
    "def PSNR(original, compressed): \n",
    "    compressed_resized = cv2.resize(compressed, (original.shape[1], original.shape[0]))\n",
    "    mse = np.mean((original - compressed_resized) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse)) \n",
    "    return psnr \n",
    "  \n",
    "def main(): \n",
    "     original = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\") \n",
    "     compressed = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c6.png\", 1) \n",
    "     value = PSNR(original, compressed) \n",
    "     print(f\"PSNR value is {value} dB\") \n",
    "       \n",
    "if __name__ == \"__main__\": \n",
    "    main() \n",
    "\n",
    "\n",
    "\n",
    "from skimage import metrics\n",
    "# Load images\n",
    "image1 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/1.png\")\n",
    "image2 = cv2.imread(\"C:/Users/Admin/Desktop/datasets/Ground_Img/c6.png\")\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "# print(image1.shape, image2.shape)\n",
    "# Convert images to grayscale\n",
    "image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Calculate SSIM\n",
    "ssim_score = metrics.structural_similarity(image1_gray, image2_gray, full=True)\n",
    "print(f\"SSIM Score: \", round(ssim_score[0], 2))\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming image1_gray and image2_gray are binary masks (0 or 255)\n",
    "binary_mask1 = (image1_gray > 0).astype(int)\n",
    "binary_mask2 = (image2_gray > 0).astype(int)\n",
    "\n",
    "# Calculate the Jaccard Index\n",
    "JI = jaccard_score(binary_mask1.flatten(), binary_mask2.flatten())\n",
    "print(\"Jaccard Index:\", JI)\n",
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "    return dice\n",
    "\n",
    "# Example usage:\n",
    "dice_score = dice_coefficient(image1_gray.astype(bool), image2_gray.astype(bool))\n",
    "print(\"Dice Score:\", dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a7db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd80c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
